{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc769ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\loss.py:529: UserWarning: Using a target size (torch.Size([500])) that is different to the input size (torch.Size([500, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_epoch --- loss: 0 1063901.5\n",
      "i_epoch --- loss: 100 812.7051391601562\n",
      "i_epoch --- loss: 200 366.4018249511719\n",
      "i_epoch --- loss: 300 263.56170654296875\n",
      "i_epoch --- loss: 400 165.64195251464844\n",
      "i_epoch --- loss: 500 139.58316040039062\n",
      "i_epoch --- loss: 600 91.9178237915039\n",
      "i_epoch --- loss: 700 82.75797271728516\n",
      "i_epoch --- loss: 800 57.550785064697266\n",
      "i_epoch --- loss: 900 57.89385986328125\n",
      "i_epoch --- loss: 1000 52.910701751708984\n",
      "i_epoch --- loss: 1100 43.54697799682617\n",
      "i_epoch --- loss: 1200 35.069847106933594\n",
      "i_epoch --- loss: 1300 32.69502639770508\n",
      "i_epoch --- loss: 1400 36.130401611328125\n",
      "i_epoch --- loss: 1500 25.98196029663086\n",
      "i_epoch --- loss: 1600 23.8746337890625\n",
      "i_epoch --- loss: 1700 25.285070419311523\n",
      "i_epoch --- loss: 1800 24.602144241333008\n",
      "i_epoch --- loss: 1900 19.613805770874023\n",
      "i_epoch --- loss: 2000 17.821739196777344\n",
      "i_epoch --- loss: 2100 18.805416107177734\n",
      "i_epoch --- loss: 2200 16.673070907592773\n",
      "i_epoch --- loss: 2300 15.890908241271973\n",
      "i_epoch --- loss: 2400 12.953330993652344\n",
      "i_epoch --- loss: 2500 12.703048706054688\n",
      "i_epoch --- loss: 2600 12.124216079711914\n",
      "i_epoch --- loss: 2700 11.18295955657959\n",
      "i_epoch --- loss: 2800 10.677515029907227\n",
      "i_epoch --- loss: 2900 12.173834800720215\n",
      "i_epoch --- loss: 3000 10.227826118469238\n",
      "i_epoch --- loss: 3100 9.708064079284668\n",
      "i_epoch --- loss: 3200 10.232654571533203\n",
      "i_epoch --- loss: 3300 8.7947998046875\n",
      "i_epoch --- loss: 3400 8.405017852783203\n",
      "i_epoch --- loss: 3500 8.478976249694824\n",
      "i_epoch --- loss: 3600 8.59872055053711\n",
      "i_epoch --- loss: 3700 7.98613977432251\n",
      "i_epoch --- loss: 3800 7.099624156951904\n",
      "i_epoch --- loss: 3900 6.871975898742676\n",
      "i_epoch --- loss: 4000 7.219306468963623\n",
      "i_epoch --- loss: 4100 6.46587610244751\n",
      "i_epoch --- loss: 4200 7.196985244750977\n",
      "i_epoch --- loss: 4300 5.863544464111328\n",
      "i_epoch --- loss: 4400 6.682971000671387\n",
      "i_epoch --- loss: 4500 5.958607196807861\n",
      "i_epoch --- loss: 4600 5.780337810516357\n",
      "i_epoch --- loss: 4700 5.796180725097656\n",
      "i_epoch --- loss: 4800 4.873367786407471\n",
      "i_epoch --- loss: 4900 5.647083282470703\n",
      "i_epoch --- loss: 5000 4.563968658447266\n",
      "i_epoch --- loss: 5100 4.690467834472656\n",
      "i_epoch --- loss: 5200 4.698628902435303\n",
      "i_epoch --- loss: 5300 4.734858989715576\n",
      "i_epoch --- loss: 5400 3.9450953006744385\n",
      "i_epoch --- loss: 5500 4.227499485015869\n",
      "i_epoch --- loss: 5600 4.546691417694092\n",
      "i_epoch --- loss: 5700 4.609644889831543\n",
      "i_epoch --- loss: 5800 4.72757625579834\n",
      "i_epoch --- loss: 5900 4.693451404571533\n",
      "i_epoch --- loss: 6000 4.5170488357543945\n",
      "i_epoch --- loss: 6100 4.0023064613342285\n",
      "i_epoch --- loss: 6200 4.024756908416748\n",
      "i_epoch --- loss: 6300 4.644336700439453\n",
      "i_epoch --- loss: 6400 4.24459171295166\n",
      "i_epoch --- loss: 6500 4.156772136688232\n",
      "i_epoch --- loss: 6600 3.097954750061035\n",
      "i_epoch --- loss: 6700 4.329692363739014\n",
      "i_epoch --- loss: 6800 3.988208770751953\n",
      "i_epoch --- loss: 6900 3.470191717147827\n",
      "i_epoch --- loss: 7000 3.5067591667175293\n",
      "i_epoch --- loss: 7100 3.1767654418945312\n",
      "i_epoch --- loss: 7200 3.431758403778076\n",
      "i_epoch --- loss: 7300 3.2010555267333984\n",
      "i_epoch --- loss: 7400 3.564284086227417\n",
      "i_epoch --- loss: 7500 3.3545663356781006\n",
      "i_epoch --- loss: 7600 3.1330366134643555\n",
      "i_epoch --- loss: 7700 2.8626930713653564\n",
      "i_epoch --- loss: 7800 2.9838485717773438\n",
      "i_epoch --- loss: 7900 2.9592325687408447\n",
      "i_epoch --- loss: 8000 2.749677896499634\n",
      "i_epoch --- loss: 8100 2.594161033630371\n",
      "i_epoch --- loss: 8200 2.8391144275665283\n",
      "i_epoch --- loss: 8300 2.6269664764404297\n",
      "i_epoch --- loss: 8400 2.8840439319610596\n",
      "i_epoch --- loss: 8500 2.4856889247894287\n",
      "i_epoch --- loss: 8600 2.854830503463745\n",
      "i_epoch --- loss: 8700 2.534820318222046\n",
      "i_epoch --- loss: 8800 3.0036470890045166\n",
      "i_epoch --- loss: 8900 2.8733580112457275\n",
      "i_epoch --- loss: 9000 2.5714328289031982\n",
      "i_epoch --- loss: 9100 2.6413967609405518\n",
      "i_epoch --- loss: 9200 2.6612441539764404\n",
      "i_epoch --- loss: 9300 2.2199251651763916\n",
      "i_epoch --- loss: 9400 2.7312653064727783\n",
      "i_epoch --- loss: 9500 2.5443506240844727\n",
      "i_epoch --- loss: 9600 2.2609505653381348\n"
     ]
    }
   ],
   "source": [
    "from pac.net2 import *\n",
    "from pac.data_gen2 import DataGen2\n",
    "from graphing import plot_heatmap\n",
    "from pac.data_loss import *\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    starttime = datetime.now()\n",
    "    # 输出数据的初始化\n",
    "    zs = 0.1\n",
    "    ze = 2\n",
    "    ts = 1\n",
    "    te = 3000\n",
    "    zsteps = 10\n",
    "    tsteps = 300\n",
    "    it_batch_size = 2000\n",
    "    bd_batch_size = 500\n",
    "    init_batch_size = 500\n",
    "    ws = 0.001\n",
    "    ds = 0.0002\n",
    "    p = 0.0001\n",
    "    # 生成数据\n",
    "\n",
    "    data = DataGen2(zs, ze, ts, te, zsteps=zsteps, tsteps=tsteps, ws=ws, ds=ds, p=p)\n",
    "    dim_in = 2\n",
    "    dim_out = 1\n",
    "    # hidden_list = (50, 40, 30, 30, 20)\n",
    "    hidden_list = (20, 10, 8, 8, 5)\n",
    "    model_name = 'DNN'\n",
    "    init_lr = 0.01\n",
    "    max_it = 10000\n",
    "\n",
    "    # 神经网络各组分的初始化\n",
    "    # model = DNN1(indim=dim_in, outdim=dim_out, hidden_units=hidden_list, name2Model=model_name, actName2in='tanh',\n",
    "    #                 actName='tanh')\n",
    "    # model = Pure_DenseNet(indim=dim_in, outdim=dim_out, hidden_units=hidden_list, name2Model=model_name, actName2in='tanh',\n",
    "    #                 actName='tanh')\n",
    "    # model = PDE_DNN(dim_in=dim_in, dim_out=dim_out, hidden_layers=hidden_list, name2Model=model_name, actName_in='tanh',\n",
    "    # actName_hidden='tanh', ws=ws, ds=ds)\n",
    "    model = PDE_DNN(dim_in=dim_in, dim_out=dim_out, hidden_layers=hidden_list, name2Model=model_name, actName_in='sin',\n",
    "                    actName_hidden='sin', ws=ws, ds=ds)\n",
    "    params2Net = model.DNN1.parameters()\n",
    "    optimizer = torch.optim.Adam(params2Net, lr=init_lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.995)\n",
    "    arr2epoch = []\n",
    "    arr2loss = []\n",
    "    arr2lr = []\n",
    "    predi = []\n",
    "    loss_append = []\n",
    "    lr_append = []\n",
    "    init_netloss = []\n",
    "    it_netloss = []\n",
    "    bd_netloss = []\n",
    "    for i_epoch in range(max_it):\n",
    "\n",
    "        # 每次迭代都随机生成数据\n",
    "        it_inputs, it_labels = data.gen_inter(it_batch_size)\n",
    "        bd_inputs, bd_labels = data.gen_bound(bd_batch_size)\n",
    "        init_inputs, init_labels = data.gen_init(init_batch_size)\n",
    "        loss1 = model.loss_init_net(init_inputs, init_labels)\n",
    "        loss2 = model.loss_it_pde(it_inputs, it_labels)\n",
    "        loss3 = model.loss_bd_net(bd_inputs, bd_labels)\n",
    "        # ds是常数损失函数修改了 内部点的pde损失\n",
    "        # loss = 1000 * model.loss_it_net(it_inputs, it_labels) + model.loss_it_pde(it_inputs, it_labels) \\\n",
    "        # + 1000 * model.loss_bd_net(bd_inputs, bd_labels)\n",
    "        loss = 100 * loss1 + loss2 + 100*loss3\n",
    "        # loss = 1000 * model.loss_init_net(init_inputs, init_labels) + model.loss_it_pde(it_inputs, it_labels) \\\n",
    "        # + 1000 * model.loss_bd_net(bd_inputs, bd_labels)\n",
    "        loss_append.append(loss.item())\n",
    "        init_netloss.append(loss1)\n",
    "        it_netloss.append(loss2)\n",
    "        bd_netloss.append(loss3)\n",
    "        lr_append.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        prediction = model.evaluate(it_inputs)\n",
    "        predi.append(prediction)\n",
    "        optimizer.zero_grad()  # 求导前先清零, 只要在下一次求导前清零即可\n",
    "        loss.backward()  # 求偏导\n",
    "        optimizer.step()  # 更新参数\n",
    "        scheduler.step()\n",
    "\n",
    "        if i_epoch % 100 == 0:\n",
    "            print('i_epoch --- loss:', i_epoch, loss.item())\n",
    "            # print(\"第%d个epoch的学习率：%f\" % (i_epoch, optimizer.param_groups[0]['lr']))\n",
    "            arr2loss.append(loss.item())\n",
    "            arr2lr.append(optimizer.param_groups[0]['lr'])\n",
    "    endtime = datetime.now()\n",
    "    print(\"RunTime: {}h-{}m-{}s\".format(endtime.hour - starttime.hour, endtime.minute - starttime.minute,\n",
    "                                        endtime.second - starttime.second))\n",
    "    # -------------show loss----------#\n",
    "    logloss = np.log(loss_append)\n",
    "    plt.title(\"log(sum loss) trend\")\n",
    "    plt.plot(logloss, color='b', label='Label')\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"log(loss)\")\n",
    "    plt.show()\n",
    "    plot_heatmap(data, model)\n",
    "    log_0 = np.log(it_netloss)\n",
    "    log_1 = np.log(bd_netloss)\n",
    "    log_2 = np.log(init_netloss)\n",
    "    log_3 = np.log(loss_append)\n",
    "    plt.title(\"loss trend\")\n",
    "    plt.plot(log_0, color='r')\n",
    "    plt.plot(log_1, color='b')\n",
    "    plt.plot(log_2, color='y')\n",
    "    plt.plot(log_3, color='g')\n",
    "    plt.legend(('interior_net loss', 'bd_net loss', 'init_net loss', 'total loss'))\n",
    "    plt.savefig(\"D:\\\\photosaved\\\\loss_comprt_iterations%d_networksizeSmall.png\" % (max_it))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
